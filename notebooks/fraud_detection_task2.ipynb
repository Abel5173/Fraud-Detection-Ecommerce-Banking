{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971b102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, confusion_matrix\n",
    "import joblib\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4348a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory paths\n",
    "DATA_DIR = os.path.join(\"../\", \"data\")\n",
    "OUTPUT_DIR = os.path.join(\"../\", \"outputs\")\n",
    "MODEL_DIR = os.path.join(OUTPUT_DIR, \"models\")\n",
    "METRICS_DIR = os.path.join(OUTPUT_DIR, \"metrics\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(METRICS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af91ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = pd.read_csv(os.path.join(OUTPUT_DIR, \"processed_fraud_data.csv\"))\n",
    "creditcard_data = pd.read_csv(os.path.join(\n",
    "    OUTPUT_DIR, \"processed_creditcard_data.csv\"))\n",
    "ip_data = pd.read_csv(os.path.join(DATA_DIR, \"IpAddress_to_Country.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfad884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, dataset_name):\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['class'])\n",
    "    y = df['class']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(f\"\\nClass distribution after SMOTE in {dataset_name} (training):\\n\", pd.Series(\n",
    "        y_train_resampled).value_counts(normalize=True))\n",
    "\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87d5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fraud_data(fraud_data, ip_data):\n",
    "    # Convert timestamps to datetime\n",
    "    fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "    fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "\n",
    "    # Create time-based features\n",
    "    fraud_data['time_since_signup'] = (\n",
    "        # Hours\n",
    "        fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds() / 3600.0\n",
    "    fraud_data['purchase_hour'] = fraud_data['purchase_time'].dt.hour\n",
    "    fraud_data['purchase_day'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "\n",
    "    # Merge with IP data to get country\n",
    "    def ip_to_country(ip):\n",
    "        for _, row in ip_data.iterrows():\n",
    "            if row['lower_bound_ip_address'] <= ip <= row['upper_bound_ip_address']:\n",
    "                return row['country']\n",
    "        return 'Unknown'\n",
    "\n",
    "    fraud_data['country'] = fraud_data['ip_address'].apply(ip_to_country)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['source', 'browser', 'sex', 'country']\n",
    "    fraud_data = pd.get_dummies(\n",
    "        fraud_data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Drop non-numeric columns\n",
    "    fraud_data = fraud_data.drop(\n",
    "        columns=['signup_time', 'purchase_time', 'user_id', 'device_id', 'ip_address'])\n",
    "\n",
    "    # Standardize column names\n",
    "    fraud_data = fraud_data.rename(columns={'class': 'class'})\n",
    "\n",
    "    # Handle missing values\n",
    "    fraud_data = fraud_data.fillna(fraud_data.mean())\n",
    "\n",
    "    return fraud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786940db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test, dataset_name):\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'logistic': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'random_forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities and labels\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "        auc_pr = auc(recall, precision)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f\"Confusion Matrix - {model_name} ({dataset_name})\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(os.path.join(\n",
    "            METRICS_DIR, f\"{dataset_name}_{model_name}_confusion_matrix.png\"))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'AUC-PR': auc_pr,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "\n",
    "        # Save model\n",
    "        joblib.dump(model, os.path.join(\n",
    "            MODEL_DIR, f\"{dataset_name}_{model_name}_model.pkl\"))\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(os.path.join(\n",
    "        METRICS_DIR, f\"{dataset_name}_metrics.csv\"), index=False)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaff15e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def justify_model_selection(fraud_results, creditcard_results):\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(\"\\nFraud_Data Metrics:\\n\", fraud_results)\n",
    "    print(\"\\ncreditcard Metrics:\\n\", creditcard_results)\n",
    "\n",
    "    # Example justification (customize based on results)\n",
    "    justification = \"\"\"\n",
    "    Model Selection Justification:\n",
    "    - Logistic Regression: Provides interpretable results, suitable for explaining fraud predictions to stakeholders. However, it may underperform on complex patterns due to its linear nature.\n",
    "    - Random Forest: Captures non-linear relationships and interactions between features, likely performing better on imbalanced data due to its ensemble nature.\n",
    "    Based on AUC-PR and F1-Score, Random Forest is selected as the best model if it shows higher performance, balancing false positives (to avoid customer inconvenience) and false negatives (to minimize financial loss). Logistic Regression is preferred if interpretability is prioritized for business needs.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(METRICS_DIR, \"model_selection_justification.txt\"), \"w\") as f:\n",
    "        f.write(justification)\n",
    "    print(justification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e457d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = preprocess_fraud_data(fraud_data, ip_data)\n",
    "fraud_X_train, fraud_X_test, fraud_y_train, fraud_y_test = prepare_data(\n",
    "    fraud_data, \"Fraud_Data\")\n",
    "creditcard_X_train, creditcard_X_test, creditcard_y_train, creditcard_y_test = prepare_data(\n",
    "    creditcard_data, \"creditcard\")\n",
    "\n",
    "# Train and evaluate models\n",
    "fraud_results = train_and_evaluate(\n",
    "    fraud_X_train, fraud_X_test, fraud_y_train, fraud_y_test, \"fraud_data\")\n",
    "creditcard_results = train_and_evaluate(\n",
    "    creditcard_X_train, creditcard_X_test, creditcard_y_train, creditcard_y_test, \"creditcard\")\n",
    "\n",
    "# Justify model selection\n",
    "justify_model_selection(fraud_results, creditcard_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
