{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import shap\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory paths for \n",
    "MODEL_DIR = \"/outputs/models\"\n",
    "SHAP_OUTPUT_DIR = \"/outputs/shap_outputs\"\n",
    "os.makedirs(SHAP_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix non-numeric columns and class values in fraud_data\n",
    "def fix_fraud_data(df):\n",
    "    # Convert timestamp columns to numeric if present\n",
    "    for col in ['signup_time', 'purchase_time']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    if 'signup_time' in df.columns and 'purchase_time' in df.columns:\n",
    "        df['time_since_signup'] = (df['purchase_time'] - df['signup_time']).dt.total_seconds() / 3600.0  # Hours\n",
    "        df['purchase_hour'] = df['purchase_time'].dt.hour\n",
    "        df['purchase_day'] = df['purchase_time'].dt.dayofweek\n",
    "        df = df.drop(columns=['signup_time', 'purchase_time'])\n",
    "\n",
    "    # Drop non-numeric identifiers\n",
    "    for col in ['user_id', 'device_id', 'ip_address']:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=[col])\n",
    "\n",
    "    # Encode categorical variables\n",
    "    categorical_cols = [col for col in df.columns if col not in ['class', 'time_since_signup', 'purchase_hour', 'purchase_day'] and df[col].dtype == 'object']\n",
    "    if categorical_cols:\n",
    "        df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Ensure numeric data\n",
    "    df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "    # Ensure class is binary {0, 1}\n",
    "    if 'class' in df.columns:\n",
    "        df['class'] = df['class'].apply(lambda x: 1 if x != 0 else 0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa221e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix creditcard_data\n",
    "def fix_creditcard_data(df):\n",
    "    # Rename 'Class' to 'class' if needed\n",
    "    df = df.rename(columns={'Class': 'class'})\n",
    "    # Ensure class is binary {0, 1}\n",
    "    if 'class' in df.columns:\n",
    "        df['class'] = df['class'].apply(lambda x: 1 if x != 0 else 0).astype(int)\n",
    "    # Ensure numeric data\n",
    "    df = df.fillna(df.mean(numeric_only=True))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd40d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shap_explanations(model, X, dataset_name):\n",
    "    # Initialize SHAP explainer for Random Forest\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "\n",
    "    # Compute SHAP values\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # For binary classification, use SHAP values for class 1 (fraud)\n",
    "    shap_values_class1 = shap_values[1]\n",
    "\n",
    "    # SHAP summary plot\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values_class1, X, show=False)\n",
    "    plt.title(f\"SHAP Summary Plot - {dataset_name} (Random Forest)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SHAP_OUTPUT_DIR, f\"{dataset_name}_shap_summary.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Save SHAP values to CSV\n",
    "    shap_df = pd.DataFrame(shap_values_class1, columns=X.columns)\n",
    "    shap_df.to_csv(os.path.join(SHAP_OUTPUT_DIR, f\"{dataset_name}_shap_values.csv\"), index=False)\n",
    "\n",
    "    # Generate feature importance (mean absolute SHAP values)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': np.abs(shap_values_class1).mean(axis=0)\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    return feature_importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fab1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_shap_report(fraud_importance, creditcard_importance=None):\n",
    "    report = \"\"\"\n",
    "    SHAP Explanation Report\n",
    "    ======================\n",
    "    This report summarizes the feature importance for fraud detection models using SHAP values.\n",
    "\n",
    "    Fraud_Data Insights:\n",
    "    - Top features contributing to fraud prediction (based on mean absolute SHAP values):\n",
    "    {}\n",
    "    - Key observations: Features like 'time_since_signup' and 'purchase_hour' likely influence fraud due to temporal patterns in fraudulent behavior.\n",
    "\n",
    "    creditcard Insights:\n",
    "    {}\n",
    "    \"\"\"\n",
    "    fraud_text = fraud_importance.head(5).to_string(index=False)\n",
    "    creditcard_text = \"Skipped due to empty dataset or processing error.\"\n",
    "    if creditcard_importance is not None:\n",
    "        creditcard_text = f\"- Top features contributing to fraud prediction:\\n{creditcard_importance.head(5).to_string(index=False)}\\n- Key observations: PCA components (e.g., V1, V2) are critical, indicating complex patterns in fraud detection.\"\n",
    "\n",
    "    report = report.format(fraud_text, creditcard_text)\n",
    "\n",
    "    with open(os.path.join(SHAP_OUTPUT_DIR, \"shap_explanation.txt\"), \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58141c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "try:\n",
    "    fraud_data = pd.read_csv('/outputs/processed_fraud_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"processed_fraud_data.csv not found. Please check the path:\")\n",
    "    !ls /kaggle/input/\n",
    "    raise\n",
    "\n",
    "creditcard_data_processed = False\n",
    "try:\n",
    "    creditcard_data = pd.read_csv('/outputs/processed_creditcard_data.csv')\n",
    "    if not creditcard_data.empty:\n",
    "        creditcard_data_processed = True\n",
    "    else:\n",
    "        print(\"Warning: processed_creditcard_data.csv is empty. Attempting to load raw creditcard.csv.\")\n",
    "        try:\n",
    "            creditcard_data = pd.read_csv('/data/creditcard.csv')\n",
    "            print(\"Loaded raw creditcard.csv as fallback.\")\n",
    "            creditcard_data_processed = True\n",
    "        except FileNotFoundError:\n",
    "            print(\"Raw creditcard.csv not found. Skipping creditcard_data processing.\")\n",
    "            creditcard_data = pd.DataFrame()\n",
    "except FileNotFoundError:\n",
    "    print(\"processed_creditcard_data.csv not found. Attempting to load raw creditcard.csv.\")\n",
    "    try:\n",
    "        creditcard_data = pd.read_csv('/data/creditcard.csv')\n",
    "        print(\"Loaded raw creditcard.csv as fallback.\")\n",
    "        creditcard_data_processed = True\n",
    "    except FileNotFoundError:\n",
    "        print(\"Raw creditcard.csv not found. Skipping creditcard_data processing.\")\n",
    "        creditcard_data = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f1cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data\n",
    "fraud_data = fix_fraud_data(fraud_data)\n",
    "if creditcard_data_processed:\n",
    "    creditcard_data = fix_creditcard_data(creditcard_data)\n",
    "\n",
    "# Verify data types and class values\n",
    "print(\"Fraud_Data dtypes:\\n\", fraud_data.dtypes)\n",
    "print(\"\\nFraud_Data class values:\\n\", fraud_data['class'].value_counts())\n",
    "if creditcard_data_processed:\n",
    "    print(\"\\ncreditcard dtypes:\\n\", creditcard_data.dtypes)\n",
    "    print(\"\\ncreditcard class values:\\n\", creditcard_data['class'].value_counts())\n",
    "\n",
    "# Load Random Forest models\n",
    "fraud_model = None\n",
    "creditcard_model = None\n",
    "try:\n",
    "    fraud_model = joblib.load(os.path.join(MODEL_DIR, \"fraud_data_random_forest_model.pkl\"))\n",
    "except FileNotFoundError:\n",
    "    print(\"fraud_data_random_forest_model.pkl not found. Check Task 2 outputs.\")\n",
    "if creditcard_data_processed:\n",
    "    try:\n",
    "        creditcard_# Load preprocessed data\n",
    "try:\n",
    "    fraud_data = pd.read_csv('/outputs/processed_fraud_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"processed_fraud_data.csv not found. Please check the path:\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_data_processed = False\n",
    "try:\n",
    "    creditcard_data = pd.read_csv('/outputs/processed_creditcard_data.csv')\n",
    "    if not creditcard_data.empty:\n",
    "        creditcard_data_processed = True\n",
    "    else:\n",
    "        print(\"Warning: processed_creditcard_data.csv is empty. Attempting to load raw creditcard.csv.\")\n",
    "        try:\n",
    "            creditcard_data = pd.read_csv('/data/creditcard.csv')\n",
    "            print(\"Loaded raw creditcard.csv as fallback.\")\n",
    "            creditcard_data_processed = True\n",
    "        except FileNotFoundError:\n",
    "            print(\"Raw creditcard.csv not found. Skipping creditcard_data processing.\")\n",
    "            creditcard_data = pd.DataFrame()\n",
    "except FileNotFoundError:\n",
    "    print(\"processed_creditcard_data.csv not found. Attempting to load raw creditcard.csv.\")\n",
    "    try:\n",
    "        creditcard_data = pd.read_csv('/data/creditcard.csv')\n",
    "        print(\"Loaded raw creditcard.csv as fallback.\")\n",
    "        creditcard_data_processed = True\n",
    "    except FileNotFoundError:\n",
    "        print(\"Raw creditcard.csv not found. Skipping creditcard_data processing.\")\n",
    "        creditcard_data = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef854f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data\n",
    "fraud_data = fix_fraud_data(fraud_data)\n",
    "if creditcard_data_processed:\n",
    "    creditcard_data = fix_creditcard_data(creditcard_data)\n",
    "\n",
    "# Verify data types and class values\n",
    "print(\"Fraud_Data dtypes:\\n\", fraud_data.dtypes)\n",
    "print(\"\\nFraud_Data class values:\\n\", fraud_data['class'].value_counts())\n",
    "if creditcard_data_processed:\n",
    "    print(\"\\ncreditcard dtypes:\\n\", creditcard_data.dtypes)\n",
    "    print(\"\\ncreditcard class values:\\n\", creditcard_data['class'].value_counts())\n",
    "\n",
    "# Load Random Forest models\n",
    "fraud_model = None\n",
    "creditcard_model = None\n",
    "try:\n",
    "    fraud_model = joblib.load(os.path.join(MODEL_DIR, \"fraud_data_random_forest_model.pkl\"))\n",
    "except FileNotFoundError:\n",
    "    print(\"fraud_data_random_forest_model.pkl not found. Check Task 2 outputs.\")\n",
    "if creditcard_data_processed:\n",
    "    try:\n",
    "        creditcard_model = joblib.load(os.path.join(MODEL_DIR, \"creditcard_random_forest_model.pkl\"))\n",
    "    except FileNotFoundError:\n",
    "        print(\"creditcard_random_forest_model.pkl not found. Skipping creditcard_data SHAP analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP explanations\n",
    "fraud_importance = None\n",
    "creditcard_importance = None\n",
    "if fraud_model is not None and not fraud_data.empty:\n",
    "    try:\n",
    "        fraud_X = fraud_data.drop(columns=['class'])\n",
    "        fraud_importance = generate_shap_explanations(fraud_model, fraud_X, \"fraud_data\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating SHAP for fraud_data: {e}\")\n",
    "\n",
    "if creditcard_model is not None and creditcard_data_processed and not creditcard_data.empty:\n",
    "    try:\n",
    "        creditcard_X = creditcard_data.drop(columns=['class'])\n",
    "        creditcard_importance = generate_shap_explanations(creditcard_model, creditcard_X, \"creditcard\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating SHAP for creditcard_data: {e}\")\n",
    "\n",
    "# Write SHAP report\n",
    "if fraud_importance is not None:\n",
    "    write_shap_report(fraud_importance, creditcard_importance)\n",
    "else:\n",
    "    print(\"Error: No SHAP explanations generated. Check input data and models.\")\n",
    "model = joblib.load(os.path.join(MODEL_DIR, \"creditcard_random_forest_model.pkl\"))\n",
    "    except FileNotFoundError:\n",
    "        print(\"creditcard_random_forest_model.pkl not found. Skipping creditcard_data SHAP analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b62bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP explanations\n",
    "fraud_importance = None\n",
    "creditcard_importance = None\n",
    "if fraud_model is not None and not fraud_data.empty:\n",
    "    try:\n",
    "        fraud_X = fraud_data.drop(columns=['class'])\n",
    "        fraud_importance = generate_shap_explanations(fraud_model, fraud_X, \"fraud_data\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating SHAP for fraud_data: {e}\")\n",
    "\n",
    "if creditcard_model is not None and creditcard_data_processed and not creditcard_data.empty:\n",
    "    try:\n",
    "        creditcard_X = creditcard_data.drop(columns=['class'])\n",
    "        creditcard_importance = generate_shap_explanations(creditcard_model, creditcard_X, \"creditcard\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating SHAP for creditcard_data: {e}\")\n",
    "\n",
    "# Write SHAP report\n",
    "if fraud_importance is not None:\n",
    "    write_shap_report(fraud_importance, creditcard_importance)\n",
    "else:\n",
    "    print(\"Error: No SHAP explanations generated. Check input data and models.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
